<!DOCTYPE html>
<html lang="es">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Sistema de Predicción de Biomasa de Cultivos</title>
    <link rel="icon" href="/img/favicon/favicon-96x96.png" type="image">
    <link rel="apple-touch-icon" href="/img/favicon/apple-icon-120x120.png">
    <link rel="canonical" href="https://australmetrics.cl/portfolio/portfolio1.html">

    <!-- Preload de Google Fonts y carga asincrónica -->
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Open+Sans:wght@400;600&family=Sumana:wght@400&display=swap" rel="stylesheet" async>

    <!-- Precarga de Font Awesome de manera eficiente -->
    <link rel="preload" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0-beta3/css/all.min.css" as="style" onload="this.rel='stylesheet'">

    <!-- Carga diferida del CSS de Prism -->
    <link rel="preload" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.24.1/themes/prism-okaidia.min.css" as="style" onload="this.rel='stylesheet'">

    <!-- CSS personalizado -->
    <style>
        /* Estilos básicos */
        :root {
            --primary-color: #007bff;
            --secondary-color: #f8f9fa;
            --text-color: #333;
            --light-gray: #e9ecef;
            --border-color: #dee2e6;
        }
        body {
            font-family: 'Open Sans', sans-serif;
            background-color: var(--secondary-color);
            color: var(--text-color);
            margin: 0;
            padding: 0;
        }
        .header {
            background-color: white;
            text-align: justify;
            padding: 5px;
            box-shadow: 0 2px 4px rgba(0,0,0,0.1);
            position: fixed;
            width: 100%;                  
        }
        .header h1 {
            font-family: 'Sumana', serif;
            font-size: 2.1em;
            text-align: center;
            margin: 0;
            padding-left: 3.3em; 
            padding-top: 0.4em;          
        }        
        .container {
            max-width: 1200px;
            margin: 0 auto;
            padding: 40px 20px;
            background-color: white;
            box-shadow: 0 0 10px rgba(0,0,0,0.1);
            padding-top: 8em;
        }
        .section {
            margin-bottom: 40px;   
            text-align: center;         
        }
        .section li {
            text-align: left;
        }
        .section-title {
            font-size: 28px;
            color: var(--primary-color);
            margin-bottom: 20px;
            border-bottom: 2px solid var(--primary-color);
            padding-bottom: 10px;
        }
        .back-button {
            position: fixed;
            top: 43px;
            left: 20px;
            background-color: #004484;
            color: #fff;
            text-decoration: none;
            padding: 10px 20px;
            border-radius: 5px;
            font-size: 16px;
            display: flex;
            align-items: center;
            transition: background-color 0.3s ease;
            z-index: 1000;
        }
        .back-button i {
            margin-right: 8px; /* Espacio entre la flecha y el texto */
        }
        .back-button:hover {
            background-color: #003366;
        }
        .subsection-title {
            font-size: 22px;
            margin-bottom: 15px;
        }
        .code-snippet {
            background-color: var(--light-gray);
            padding: 15px;
            border-radius: 4px;
            margin-bottom: 20px;
            border: 1px solid var(--border-color);
            overflow-x: auto;
        }
        .testimonial {
            background-color: var(--light-gray);
            padding: 20px;
            border-radius: 4px;
            margin-bottom: 20px;
            font-style: italic;
        }
        .tech-tools-grid {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(200px, 1fr));
            gap: 20px;
            margin-top: 20px;
        }
        .tech-tool-item {
            background-color: white;
            border: 1px solid var(--border-color);
            border-radius: 4px;
            padding: 20px;
            text-align: center;
            transition: all 0.3s ease;
        }
        .tech-tool-item:hover {
            box-shadow: 0 5px 15px rgba(0,0,0,0.1);
            transform: translateY(-5px);
        }
        .tech-tool-icon {
            font-size: 2.5em;
            color: var(--primary-color);
            margin-bottom: 10px;
        }
        .footer {
            background-color: var(--text-color);
            color: white;
            text-align: center;
            padding: 20px;
            margin-top: 40px;
        }
        .cta-button {
            display: inline-block;
            padding: 10px 20px;
            background-color: var(--primary-color);
            color: white;
            text-decoration: none;
            border-radius: 4px;
            margin-top: 20px;
        }
        .step-icon {
            font-size: 2em;
            color: var(--primary-color);
            margin-bottom: 10px;
        }
        .p2 {
            text-align: left;
        }
        h3 {
            text-align: left;
        }

        @media (max-width: 768px) {
            .container {
                padding: 20px 10px;
            }
        }
    </style>
</head>
<body>
    <div class="header">
        <h1>Método de aumento de datos basado en modelos de difusión guiados por texto para la detección de brotes en viñedos</h1>
        <a href="/index.html" class="back-button">
            <i class="fas fa-arrow-left"></i> Volver
        </a>
    </div>

    <div class="container">
        <div class="section">
            <h2 class="section-title">Descripción del Proyecto</h2>            
            <p class="p2">El estudio propone un método de aumento de datos generativo llamado D4, que utiliza un modelo de difusión guiado por texto para mejorar la detección de brotes en viñedos. Este método aborda los desafíos de la escasez de datos de entrenamiento y la diversidad de dominios en la agricultura, generando imágenes anotadas que preservan la información necesaria para la detección de objetos. Los resultados muestran mejoras significativas en la precisión de detección, lo que sugiere que D4 puede ser una solución efectiva para la agricultura de precisión.</p>
            <!-- <p class="p2">Solución: Se propone un sistema que:</p>
            <ul>
                <li>Segmenta los peces planos en partes de cabeza, aletas y cuerpo.</li>
                <li>Aumenta el conjunto de datos utilizando GAN para generar imágenes realistas de enfermedades.</li>
                <li>Utiliza YOLOv8 para la detección de enfermedades, mejorando el rendimiento mediante la segmentación y la ampliación de datos.</li>
            </ul> -->
            <img class="p3"  src="/img/Portfolio/portfolio5.webp" alt="Proyecto de aumento de imágenes en viñedos" width="600" height="400" style="border-radius: 4px;" loading="lazy">
        </div>

        <div class="section">
            <h2 class="section-title">Enfoque Técnico</h2>
            <h3 class="subsection-title">
                <i class="fas fa-image step-icon"></i>
                Paso 1: Recolección de Datos
            </h3>
            <p class="p2">Se utilizan vehículos aéreos no tripulados (UAV) para capturar videos de viñedos durante el día y la noche. Esto permite obtener una gran cantidad de imágenes de diferentes condiciones ambientales.</p>
            <div class="code-snippet">
                <pre><code class="language-python">
import torch
import torch.nn as nn
import torchvision.transforms as transforms
import torchvision.models as models
from pymongo import MongoClient
import numpy as np
import random
import cv2
import os

# Configuración de MongoDB
client = MongoClient('mongodb://localhost:27017/')
db = client['vineyard_db']
collection = db['images']

# Transformaciones para las imágenes
transform = transforms.Compose([
    transforms.ToPILImage(),
    transforms.Resize((256, 256)),
    transforms.RandomHorizontalFlip(),
    transforms.RandomVerticalFlip(),
    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.2),
    transforms.ToTensor(),
])

def preprocess_images(image_path, image_type='satellite'):    
    image = cv2.imread(image_path)
    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)    
    if image is None:
        raise ValueError(f"Error al cargar la imagen en {image_path}")


    image_resized = cv2.resize(image, (512, 512))    
    image_normalized = image_resized / 255.0    
    gray_image = cv2.cvtColor(image_resized, cv2.COLOR_BGR2GRAY)    
    edges = cv2.Canny(gray_image, 100, 200)    
    blurred_image = cv2.GaussianBlur(image_resized, (5, 5), 0)    
    color_hist = cv2.calcHist([image_resized], [0, 1, 2], None, [8, 8, 8], [0, 256, 0, 256, 0, 256])
    color_hist = cv2.normalize(color_hist, color_hist).flatten()    
    _, thresholded = cv2.threshold(gray_image, 128, 255, cv2.THRESH_BINARY)

    # Morfología (dilatación y erosión)
    kernel = np.ones((5, 5), np.uint8)
    morphed_image = cv2.morphologyEx(thresholded, cv2.MORPH_CLOSE, kernel)

    
    contours, _ = cv2.findContours(morphed_image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
    contour_image = np.zeros_like(gray_image)
    cv2.drawContours(contour_image, contours, -1, (255, 255, 255), thickness=2)

    # Extracción de características espectrales
    if image_type == 'spectral':        
        spectral_means = np.mean(image_normalized, axis=(0, 1))  # Media de cada canal
        spectral_variances = np.var(image_normalized, axis=(0, 1))  # Varianza de cada canal
    else:
        spectral_means = spectral_variances = None

    # Retorno de la imagen preprocesada y características
    processed_data = {
        'normalized_image': image_normalized,
        'gray_image': gray_image,
        'edges': edges,
        'blurred_image': blurred_image,
        'color_hist': color_hist,
        'thresholded_image': thresholded,
        'contour_image': contour_image,
        'spectral_means': spectral_means,
        'spectral_variances': spectral_variances
    }

    return processed_data   
                </code></pre>
            </div>
            <h3 class="subsection-title">
                <i class="fas fa-arrow-up-from-bracket step-icon"></i>
                Paso 2: Anotación de Imágenes
            </h3>
            <p class="p2">Se seleccionan imágenes nocturnas de alta calidad y se anotan manualmente para identificar los brotes y sus nodos. Esta anotación es crucial para entrenar el modelo de detección.</p>
            <img class="p3" src="/img/Portfolio/portfolio5_dl1.webp" alt="Anotación de imágenes" width="600" height="400" style="border-radius: 4px;" loading="lazy">           
            <h3 class="subsection-title">
                <i class="fas fa-chart-line step-icon"></i>
                Paso 3: Entrenamiento del Modelo D4
            </h3>
            <p class="p2">Se entrena el modelo D4 utilizando las imágenes anotadas y un conjunto de datos de imágenes diurnas. El modelo aprende a generar imágenes diurnas a partir de las nocturnas, adaptándose a las variaciones de dominio.</p>
            <img class="p3" src="/img/Portfolio/portfolio5_dl2.webp" alt="Entrenamiento del modelo D4" width="600" height="400" style="border-radius: 4px;" loading="lazy">

            <h3 class="subsection-title">
                <i class="fas fa-gears step-icon"></i>
                Paso 4: Generación de Imágenes Sintéticas
            </h3>
            <p class="p2">D4 genera un gran número de imágenes diurnas sintéticas que son anotadas automáticamente, lo que aumenta la diversidad del conjunto de datos y mejora la precisión del modelo.</p>

            <h3 class="subsection-title">
                <i class="fas fa-chart-line step-icon"></i>
                Paso 5: Evaluación y Optimización
            </h3>
            <p class="p2">Se evalúa el rendimiento del modelo utilizando métricas de precisión media (mAP) y se ajustan los parámetros del modelo para maximizar la precisión en la detección de brotes.</p>
        </div>

        <div class="section">
            <h2 class="section-title">Resultados y Beneficios</h2>
            <ul>
                <li><strong>Mejora en rendimiento:</strong> Se logró un 20% más de rendimiento utilizando el aumento de datos ya que con ello es posible generalizar modelos donde no se cuenta con mucha data.</li>
                <li><strong>Generalización:</strong> El sistema es generalizable a otros viñedos, y es posible adaptar D4 a otras plantaciones a condiciones similares.</li>                
            </ul>
        </div>
        <div class="testimonial">
            <p>Viñedos del Sur, una empresa vitivinícola en el Valle de Colchagua, implementó el modelo D4 para optimizar la detección de brotes en sus viñedos. Gracias a esta tecnología, lograron aumentar su rendimiento en un 20% y mejorar la calidad de sus uvas, posicionándose como líderes en innovación agrícola en la región"</p>
            <p><strong>- José Covarrubias, Gerente de Viñedos del Sur</strong></p>
        </div>
        <div class="section">
            <h2 id="tech-tools-section" class="section-title">Tecnologías y Herramientas</h2>
            <div class="tech-tools-grid">
                <div class="tech-tool-item">
                    <i class="fab fa-python tech-tool-icon"></i>
                    <h4>Python</h4>
                    <p>Lenguaje principal de desarrollo</p>
                </div>
                <div class="tech-tool-item">
                    <i class="fas fa-brain tech-tool-icon"></i>
                    <h4>PyTorch</h4>
                    <p>Framework de deep learning</p>
                </div>
                <div class="tech-tool-item">
                    <i class="fas fa-chalkboard tech-tool-icon"></i>
                    <h4>OpenCV</h4>
                    <p>Framework de Procesamiento de imágenes</p>
                </div>
                <div class="tech-tool-item">
                    <i class="fas fa-database tech-tool-icon"></i>
                    <h4>MongoDB</h4>
                    <p>Base de datos para almacenamiento</p>
                </div>
                <div class="tech-tool-item">
                    <i class="fas fa-cloud tech-tool-icon"></i>
                    <h4>Microsoft Azure</h4>
                    <p>Infraestructura en la nube</p>
                </div>
                <div class="tech-tool-item">
                    <i class="fas fa-brain tech-tool-icon"></i>
                    <h4>Scikit-learn</h4>
                    <p>Infraestructura en la nube</p>
                </div>
                <div class="tech-tool-item">
                    <i class="fas fa-square-poll-vertical tech-tool-icon"></i>
                    <h4>Pandas</h4>
                    <p>Manejo y análisis de datos tabulares</p>
                </div>
                <div class="tech-tool-item">
                    <i class="fas fa-cubes tech-tool-icon"></i>
                    <h4>Numpy</h4>
                    <p>Operaciones matemáticas sobre matrices y tensores, esencial para cálculos de deep learning</p>
                </div>
                <div class="tech-tool-item">
                    <i class="fas fa-docker tech-tool-icon"></i>
                    <h4>Docker</h4>
                    <p>Para crear entornos consistentes y reproducibles durante el desarrollo y despliegue</p>
                </div>
                <div class="tech-tool-item">
                    <i class="fas fa-code-fork tech-tool-icon"></i>
                    <h4>DVC</h4>
                    <p>Para el control de versiones de los datos y el modelo</p>
                </div>
                <div class="tech-tool-item">
                    <i class="fas fa-qrcode tech-tool-icon"></i>
                    <h4>FastAPI</h4>
                    <p>Framework ligero para crear APIs RESTful y exponer el modelo como servicio web</p>
                </div>
                <div class="tech-tool-item">
                    <i class="fas fa-shield tech-tool-icon"></i>
                    <h4>SSL/TLS</h4>
                    <p>Certificados de seguridad para asegurar las comunicaciones entre servicios</p>
                </div>
                <div class="tech-tool-item">
                    <i class="fas fa-chart-bar tech-tool-icon"></i>
                    <h4>Matplotlib</h4>
                    <p>Visualización de datos</p>
                </div>
                <div class="tech-tool-item">
                    <i class="fas fa-brain tech-tool-icon"></i>
                    <h4>Ultralytics YOLOv8</h4>
                    <p>Modelo de segmentación de imágenes y detección de objetos en tiempo real</p>
                </div>
                <div class="tech-tool-item">
                    <i class="fas fa-code-branch tech-tool-icon"></i>
                    <h4>Git</h4>
                    <p>Control de versiones</p>
                </div>
            </div>
        </div>

        <div class="section">
            <h2 class="section-title">¿Listo para optimizar tus cultivos?</h2>
            <a href="#contact" class="cta-button">Solicitar una Demostración</a>
        </div>
    </div>

    <footer class="footer">
        <p>&copy; 2024 Austral Metrics. Todos los derechos reservados.</p>
    </footer>

    <!-- Carga diferida de Prism JS -->
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.24.1/prism.min.js" defer></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.24.1/components/prism-python.min.js" defer></script>
</body>
</html>